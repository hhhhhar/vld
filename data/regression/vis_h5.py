import h5py
import matplotlib
matplotlib.use("Qt5Agg")
import matplotlib.pyplot as plt
import numpy as np
import torch

intrinsic = np.array([[732.9993,   0.0000, 320.0000],
         [  0.0000, 732.9993, 240.0000],
         [  0.0000,   0.0000,   1.0000]])

def print_h5_tree(h5_path):
    def visitor(name, obj):
        # è®¡ç®—ç¼©è¿›å±‚çº§
        depth = name.count('/')
        indent = "  " * depth

        if isinstance(obj, h5py.Group):
            print(f"{indent}+ [G] {name}/")
        elif isinstance(obj, h5py.Dataset):
            shape = obj.shape
            dtype = obj.dtype
            print(f"{indent}- [D] {name}    shape={shape} dtype={dtype}")

    with h5py.File(h5_path, 'r') as f:
        print(f"H5 file: {h5_path}")
        f.visititems(visitor)
        # for img in f["rgb"]:
        #     plt.figure(figsize=(10, 6))
        #     plt.imshow(img)
        #     plt.show()
        cam_mat = f["cam_mat"][:]
        print(cam_mat)
        for depth_isaac in f["distance_to_image_plane"]:
            bbox = f["scaled_bbox"][()].squeeze(1)

            depth_isaac = depth_isaac.squeeze(-1)
            plt.figure(figsize=(10, 6))
            plt.imshow(depth_isaac)
            plt.show()
            pcd_cam = depth_to_world_pointcloud(depth_isaac, intrinsic, cam_mat, to_world=True)
            try:
                import open3d as o3d
                print("\nğŸ¨ æ­£åœ¨å¯åŠ¨ Open3D å¯è§†åŒ–çª—å£...")
                print("   (æŒ‰ 'Q' é”®é€€å‡ºçª—å£)")

                spheres_list = []
    
                for point in bbox:
                    # 1. åˆ›å»ºä¸€ä¸ªçƒä½“ç½‘æ ¼ (ä»£æ›¿ PointCloud)
                    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.01)
                    
                    # 2. å°†çƒä½“ç§»åŠ¨åˆ°å¯¹åº”çš„è§’ç‚¹ä½ç½®
                    sphere.translate(point)
                    
                    # 3. è®¾ç½®é¢œè‰²
                    sphere.paint_uniform_color([1, 0, 0])
                    
                    # 4. ä¸ºäº†å¹³æ»‘æ˜¾ç¤ºï¼Œè®¡ç®—ä¸€ä¸‹æ³•çº¿
                    sphere.compute_vertex_normals()
                    
                    spheres_list.append(sphere)
                
                # 5. å°†è¿™ 8 ä¸ªçƒä½“åˆå¹¶æˆä¸€ä¸ª Mesh å¯¹è±¡ï¼Œæ–¹ä¾¿åç»­è°ƒç”¨ draw_geometries
                #    (Open3D æ”¯æŒç”¨ += è¿ç®—ç¬¦åˆå¹¶ Mesh)
                combined_mesh = spheres_list[0]
                for i in range(1, len(spheres_list)):
                    combined_mesh += spheres_list[i]
                
                # è½¬ä¸º Numpy CPU
                pcd_np = pcd_cam.cpu().numpy()  

                # åˆ›å»º Open3D å¯¹è±¡
                pcd_o3d = o3d.geometry.PointCloud()
                pcd_o3d.points = o3d.utility.Vector3dVector(pcd_np)
                
                # æ·»åŠ ä¸€ä¸ªåæ ‡è½´ (çº¢X, ç»¿Y, è“Z) ç”¨ä½œä¸–ç•ŒåŸç‚¹å‚è€ƒ
                origin_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1.0, origin=[0, 0, 0])
                
                # ä¸ºäº†å±•ç¤ºç›¸æœºä½ç½®ï¼Œæˆ‘ä»¬åœ¨ç›¸æœºä½ç½®ä¹Ÿç”»ä¸ªå°åæ ‡è½´
                cam_pos_np = cam_mat[:3, 3]
                cam_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5)
                cam_frame.translate(cam_pos_np)
                
                o3d.visualization.draw_geometries([pcd_o3d, origin_frame, cam_frame, combined_mesh], 
                                                window_name="Isaac Lab World Point Cloud")
            except ImportError:
                print("âš ï¸ æœªå®‰è£… Open3Dï¼Œæ— æ³•è¿›è¡Œç‚¹äº‘å¯è§†åŒ–ã€‚è¯·å®‰è£… open3d åº“åé‡è¯•ã€‚")


        for seg in f["semantic_segmentation"]:
            seg = torch.from_numpy(seg)
            rgb_channels = seg[..., :3]

            # æ­¥éª¤ B: åˆ›å»ºæ©ç  (Mask)
            # é€»è¾‘ï¼šåœ¨æœ€åä¸€ä¸ªç»´åº¦ä¸Š(dim=-1)ï¼Œåªè¦æœ‰ä»»ä½•ä¸€ä¸ªå€¼(any)ä¸ç­‰äº0ï¼Œå°±ä¸º True
            # mask shape: (H, W)
            is_valid_mask = torch.any(rgb_channels != 0, dim=-1)

            # ä¹Ÿå¯ä»¥ç”¨ sum æ–¹æ³• (å¯¹äº uint8 ç±»å‹ï¼Œsum > 0 ç­‰ä»·äºä»»ä½•ä¸€ä¸ªä¸ä¸º0)
            # is_valid_mask = rgb_channels.sum(dim=-1) > 0

            valid_coords = torch.nonzero(is_valid_mask, as_tuple=False)

            print(f"\n--- 2. æ‰¾åˆ° {len(valid_coords)} ä¸ªæœ‰æ•ˆåƒç´ çš„åæ ‡ ---")
            plt.figure(figsize=(10, 6))
            plt.imshow(seg, cmap='jet', interpolation='nearest')
            plt.show()

def depth_to_world_pointcloud(depth_tensor, intrinsic_matrix, camera_pose_4x4, device="cuda", to_world=False):
    """
    å°† Isaac Lab çš„ depth (distance_to_image_plane) è½¬æ¢ä¸ºä¸–ç•Œåæ ‡ç³»ç‚¹äº‘ã€‚
    
    å‚æ•°:
        depth_tensor (torch.Tensor): (H, W) æ·±åº¦å›¾
        intrinsic_matrix (torch.Tensor): (3, 3) ç›¸æœºå†…å‚ K
        camera_pose_4x4 (torch.Tensor): (4, 4) ç›¸æœºåˆ°ä¸–ç•Œçš„å˜æ¢çŸ©é˜µ (Camera-to-World Pose)
        device (str): è¿è¡Œè®¾å¤‡
        to_world (bool): æ˜¯å¦è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³» (é»˜è®¤ Falseï¼Œåªè¿”å›ç›¸æœºåæ ‡ç³»ä¸‹çš„ç‚¹äº‘)
        
    è¿”å›:
        torch.Tensor: (N, 3) ä¸–ç•Œåæ ‡ç³»ä¸‹çš„ç‚¹äº‘
    """
    # 1. æ•°æ®å‡†å¤‡ä¸è®¾å¤‡ç§»åŠ¨
    depth_tensor = torch.from_numpy(depth_tensor).float()
    intrinsic_matrix = torch.from_numpy(intrinsic_matrix).float()
    camera_pose_4x4 = torch.from_numpy(camera_pose_4x4).float()

    if depth_tensor.device.type != device:
        depth_tensor = depth_tensor.to(device)
    if intrinsic_matrix.device.type != device:
        intrinsic_matrix = intrinsic_matrix.to(device)
    if camera_pose_4x4.device.type != device:
        camera_pose_4x4 = camera_pose_4x4.to(device)
    H, W = depth_tensor.shape
    
    # 2. æå–å†…å‚
    fx, fy = intrinsic_matrix[0, 0], intrinsic_matrix[1, 1]
    cx, cy = intrinsic_matrix[0, 2], intrinsic_matrix[1, 2]
    
    # 3. ç”Ÿæˆåƒç´ ç½‘æ ¼ (u, v)
    # indexing='ij' -> v(è¡Œ/é«˜), u(åˆ—/å®½)
    v_grid, u_grid = torch.meshgrid(
        torch.arange(H, device=device, dtype=torch.float32),
        torch.arange(W, device=device, dtype=torch.float32),
        indexing='ij'
    )
    
    # 4. åæŠ•å½± (Back-projection) åˆ°ç›¸æœºåæ ‡ç³»
    # è¿™é‡Œä½¿ç”¨çš„æ˜¯æ ‡å‡†é’ˆå­”ç›¸æœºæ¨¡å‹ (OpenCV Convention)
    # åæ ‡ç³»å®šä¹‰: +Z å‰, +X å³, +Y ä¸‹
    z = depth_tensor
    x = (u_grid - cx) * z / fx
    y = (v_grid - cy) * z / fy
    
    # å †å ä¸º (N, 3) çŸ©é˜µ
    points_cam_cv = torch.stack([x, y, z], dim=-1).reshape(-1, 3)
    
    # 5. ã€å…³é”®æ­¥éª¤ã€‘åæ ‡ç³»ä¿®æ­£
    # Isaac Sim çš„ Camera Prim (USD) åæ ‡ç³»å®šä¹‰ä¸º: -Z å‰, +Y ä¸Š, +X å³
    # è€Œä¸Šé¢çš„è®¡ç®—ç»“æœæ˜¯: +Z å‰, +Y ä¸‹, +X å³
    # å¿…é¡»å°†ç‚¹ä» "CV Frame" æ—‹è½¬åˆ° "USD Camera Frame" æ‰èƒ½åº”ç”¨ pose çŸ©é˜µ
    # å˜æ¢é€»è¾‘: x -> x, y -> -y, z -> -z
    
    correction_vector = torch.tensor([1.0, -1.0, -1.0], device=device)
    points = points_cam_cv * correction_vector
    
    if to_world:
        # 6. è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
        # æå–æ—‹è½¬ R (3x3) å’Œ å¹³ç§» T (3)
        R = camera_pose_4x4[:3, :3]
        T = camera_pose_4x4[:3, 3]
        
        # åº”ç”¨å…¬å¼: P_world = R * P_local + T
        # çŸ©é˜µä¹˜æ³•æ³¨æ„: points æ˜¯ (N, 3), R æ˜¯ (3, 3)
        # çº¿æ€§ä»£æ•°å†™æ³•åº”ä¸º (R @ points.T).T + T
        # ç®€åŒ–ä»£ç å†™æ³•ä¸º points @ R.T + T
        points = points @ R.T + T
    
    # 7. è¿‡æ»¤æ— æ•ˆç‚¹ (å¯é€‰)
    # è¿‡æ»¤æ‰æ·±åº¦ä¸ºæ— ç©·å¤§(å¤©ç©º)æˆ– 0 çš„ç‚¹
    valid_mask = (z.reshape(-1) > 0.0) & (z.reshape(-1) < 1000.0)
    points = points[valid_mask]
    
    return points


print_h5_tree("/home/hhhar/liuliu/vld/data/regression/data_res/data_0001.h5")